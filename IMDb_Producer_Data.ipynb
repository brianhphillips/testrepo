{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPDEMKtHwM3RguK10rGZqAV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/brianhphillips/testrepo/blob/main/IMDb_Producer_Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oSAFu1Oy5H8O",
        "outputId": "078097b4-2792-4add-f3e4-55f14af9029d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# STEP 1: Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 2: Import Libraries\n",
        "import pandas as pd\n",
        "\n",
        "# Change this path to wherever you've stored your IMDb .tsv files\n",
        "BASE_PATH = \"/content/drive/MyDrive/\""
      ],
      "metadata": {
        "id": "mQCj2Pdl5L6t"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 3: Load only the necessary columns to reduce memory usage\n",
        "\n",
        "# List of target producers\n",
        "producer_names = [\n",
        "    \"Jon Landau\", \"Mark Nielsen\", \"Jon Favreau\", \"Jonas Rivera\", \"J.K. Rowling\",\n",
        "    \"Kevin Feige\", \"Zane Weiner\", \"James Cameron\", \"Janet Healy\", \"Tom DeSanto\",\n",
        "    \"Darla Anderson\", \"Bryan Burk\", \"Carolynne Cunningham\", \"Christopher McQuarrie\",\n",
        "    \"Christopher Nolan\", \"Michael Fottrell\", \"Simon Emanuel\", \"Melissa Cobb\"\n",
        "]\n",
        "\n",
        "# name.basics.tsv - to get nconst for each name\n",
        "names = pd.read_csv(\n",
        "    BASE_PATH + \"name.basics.tsv\",\n",
        "    sep=\"\\t\",\n",
        "    usecols=[\"nconst\", \"primaryName\"],\n",
        "    dtype=str,\n",
        "    na_values=\"\\\\N\"\n",
        ")\n",
        "matched_names = names[names['primaryName'].isin(producer_names)]"
      ],
      "metadata": {
        "id": "MUjz21YR5Nkt"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set chunk size (you can tune this if needed)\n",
        "CHUNK_SIZE = 100_000\n",
        "\n",
        "# Keep track of rows that match our producers\n",
        "filtered_producer_rows = []\n",
        "\n",
        "# Convert matched nconsts to a set for fast lookup\n",
        "target_nconsts = set(matched_names['nconst'])\n",
        "\n",
        "# Path to principals file\n",
        "principals_path = BASE_PATH + \"title.principals.tsv\"\n",
        "\n",
        "# Read in chunks\n",
        "with pd.read_csv(\n",
        "    principals_path,\n",
        "    sep=\"\\t\",\n",
        "    usecols=[\"tconst\", \"nconst\", \"category\"],\n",
        "    dtype=str,\n",
        "    na_values=\"\\\\N\",\n",
        "    chunksize=CHUNK_SIZE\n",
        ") as reader:\n",
        "    for chunk in reader:\n",
        "        # Filter rows that match the producer nconsts AND category = \"producer\"\n",
        "        filtered = chunk[\n",
        "            (chunk[\"nconst\"].isin(target_nconsts)) &\n",
        "            (chunk[\"category\"].str.lower() == \"producer\")\n",
        "        ]\n",
        "        filtered_producer_rows.append(filtered)\n",
        "\n",
        "# Concatenate all filtered rows\n",
        "producers = pd.concat(filtered_producer_rows, ignore_index=True)"
      ],
      "metadata": {
        "id": "d5FPI7Lu5Pm6"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 5: Load title.basics.tsv and filter to movies only\n",
        "\n",
        "titles = pd.read_csv(\n",
        "    BASE_PATH + \"title.basics.tsv\",\n",
        "    sep=\"\\t\",\n",
        "    usecols=[\"tconst\", \"titleType\"],\n",
        "    dtype=str,\n",
        "    na_values=\"\\\\N\"\n",
        ")\n",
        "titles = titles[titles[\"titleType\"] == \"movie\"]"
      ],
      "metadata": {
        "id": "0R61vRdH5Rqr"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 6: Join producers with movies\n",
        "producer_movies = producers.merge(titles, on=\"tconst\")"
      ],
      "metadata": {
        "id": "mffPdz_b5TsZ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 7: Load title.ratings.tsv and join ratings\n",
        "ratings = pd.read_csv(\n",
        "    BASE_PATH + \"title.ratings.tsv\",\n",
        "    sep=\"\\t\",\n",
        "    usecols=[\"tconst\", \"averageRating\"],\n",
        "    dtype={'tconst': str, 'averageRating': float},\n",
        "    na_values=\"\\\\N\"\n",
        ")\n",
        "\n",
        "# Merge ratings with producer-movie data\n",
        "producer_movies_rated = producer_movies.merge(ratings, on=\"tconst\")"
      ],
      "metadata": {
        "id": "c7BnwvOO5VkK"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 8: Add back producer names and calculate average scores\n",
        "producer_movies_named = producer_movies_rated.merge(matched_names, on=\"nconst\")\n",
        "\n",
        "# Group by name and compute average rating\n",
        "average_scores = producer_movies_named.groupby(\"primaryName\")[\"averageRating\"].mean().reset_index()\n",
        "\n",
        "# Sort (optional)\n",
        "average_scores = average_scores.sort_values(by=\"averageRating\", ascending=False)\n",
        "\n",
        "# Display\n",
        "print(average_scores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E9R9pJcR5XIc",
        "outputId": "af5f9bed-5b23-4190-ee3d-85f26ca57350"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              primaryName  averageRating\n",
            "3       Christopher Nolan       8.130000\n",
            "9            Jonas Rivera       8.000000\n",
            "11           Mark Nielsen       7.550000\n",
            "1    Carolynne Cunningham       7.450000\n",
            "16            Zane Weiner       7.450000\n",
            "2   Christopher McQuarrie       7.366667\n",
            "12           Melissa Cobb       7.333333\n",
            "5           James Cameron       7.200000\n",
            "10            Kevin Feige       7.188889\n",
            "4            J.K. Rowling       7.140000\n",
            "8              Jon Landau       7.133333\n",
            "14          Simon Emanuel       7.066667\n",
            "0              Bryan Burk       6.977778\n",
            "7             Jon Favreau       6.925000\n",
            "6             Janet Healy       6.683333\n",
            "13       Michael Fottrell       6.642857\n",
            "15            Tom DeSanto       6.300000\n"
          ]
        }
      ]
    }
  ]
}